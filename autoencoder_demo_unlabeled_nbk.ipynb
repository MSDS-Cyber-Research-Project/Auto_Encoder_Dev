{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken from https://github.com/aaxwaz/Fraud-detection-using-deep-learning/blob/master/auto-encoder/autoencoder_demo.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from datetime import datetime \n",
    "from sklearn.metrics import roc_auc_score as auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Shape: (296542, 11)\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('/host/data/data_exploration_output_1000lines.csv')\n",
    "df = pd.read_csv('data_exploration_filtered_lat.csv')\n",
    "\n",
    "#cols = [\"time\",\"p(src_user)\",\"p(dest_user)\",\"p(src_nt_host)\",\"p(dest_nt_host)\",\"p(src_user n dest_user)\",\"p(src_nt_host n dest_nt_host)\",\"p(dest_user n dest_nt_host)\",\"p(src_nt_host|dest_nt_host)\",\"p(dest_user|src_user)\",\"p(dest_nt_host|dest_user)\"]\n",
    "cols = [\"p(src_user)\",\"p(dest_user)\",\"p(src_nt_host)\",\"p(dest_nt_host)\",\"p(src_user n dest_user)\",\"p(src_nt_host n dest_nt_host)\",\"p(dest_user n dest_nt_host)\",\"p(src_nt_host|dest_nt_host)\",\"p(dest_user|src_user)\",\"p(dest_nt_host|dest_user)\", \"is_malicious\"]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "print(\"DF Shape: \" + str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(src_user)</th>\n",
       "      <th>p(dest_user)</th>\n",
       "      <th>p(src_nt_host)</th>\n",
       "      <th>p(dest_nt_host)</th>\n",
       "      <th>p(src_user n dest_user)</th>\n",
       "      <th>p(src_nt_host n dest_nt_host)</th>\n",
       "      <th>p(dest_user n dest_nt_host)</th>\n",
       "      <th>p(src_nt_host|dest_nt_host)</th>\n",
       "      <th>p(dest_user|src_user)</th>\n",
       "      <th>p(dest_nt_host|dest_user)</th>\n",
       "      <th>is_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.024452</td>\n",
       "      <td>0.607917</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.024452</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.607917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p(src_user)  p(dest_user)  p(src_nt_host)  p(dest_nt_host)  \\\n",
       "0     0.004138      0.004138        0.024452         0.607917   \n",
       "\n",
       "   p(src_user n dest_user)  p(src_nt_host n dest_nt_host)  \\\n",
       "0                 0.000017                       0.014865   \n",
       "\n",
       "   p(dest_user n dest_nt_host)  p(src_nt_host|dest_nt_host)  \\\n",
       "0                     0.002516                     0.024452   \n",
       "\n",
       "   p(dest_user|src_user)  p(dest_nt_host|dest_user)  is_malicious  \n",
       "0               0.004138                   0.607917             0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_RATIO = 0.25\n",
    "#df.sort_values('time', inplace = True)\n",
    "TRA_INDEX = int((1-TEST_RATIO) * df.shape[0])\n",
    "#train_x = df.iloc[:TRA_INDEX, 1:-2].values\n",
    "train_x = df.iloc[:TRA_INDEX, 0:-1].values\n",
    "#train_x = df.iloc[:TRA_INDEX, :].values\n",
    "train_y = df.iloc[:TRA_INDEX, -1].values\n",
    "#train_y = df.iloc[:TRA_INDEX, :].values\n",
    "\n",
    "#test_x = df.iloc[TRA_INDEX:, 1:-2].values\n",
    "test_x = df.iloc[TRA_INDEX:, 0:-1].values\n",
    "#test_x = df.iloc[TRA_INDEX:, :].values\n",
    "test_y = df.iloc[TRA_INDEX:, -1].values\n",
    "#test_y = df.iloc[TRA_INDEX:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train examples: 222406, total malicious cases: 5, equal to 0.00002 of total cases. \n",
      "Total test examples: 74136, total malicious cases: 101, equal to 0.00136 of total cases. \n"
     ]
    }
   ],
   "source": [
    "print(\"Total train examples: {}, total malicious cases: {}, equal to {:.5f} of total cases. \".format(train_x.shape[0], np.sum(train_y), np.sum(train_y)/train_x.shape[0]))\n",
    "\n",
    "print(\"Total test examples: {}, total malicious cases: {}, equal to {:.5f} of total cases. \".format(test_x.shape[0], np.sum(test_y), np.sum(test_y)/test_y.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Modelling and results\n",
    "# \n",
    "\n",
    "# ## 1. Auto-encoder as unsupervised learning\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "#training_epochs = 500\n",
    "batch_size = 256\n",
    "#batch_size = 32\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 15 # 1st layer num features\n",
    "n_hidden_2 = 15 # 2nd layer num features\n",
    "n_input = train_x.shape[1] # MNIST data input (img shape: 28*28)\n",
    "data_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Train and val the model - (1 hidden layer turned out to be enough)\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    #'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "    #'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    #'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([n_input])),\n",
    "    #'decoder_b2': tf.Variable(tf.random_normal([n_input])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                   biases['encoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    #layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "                                   #biases['encoder_b2']))\n",
    "    return layer_1\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "                                   biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    #layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "                                   #biases['decoder_b2']))\n",
    "    return layer_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "\n",
    "# Define batch mse\n",
    "batch_mse = tf.reduce_mean(tf.pow(y_true - y_pred, 2), 1)\n",
    "\n",
    "#print(\"========= Batch MSE Shape =========\")\n",
    "#print(batch_mse.shape)\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# TRAIN StARTS\n",
    "save_model = os.path.join(data_dir, 'temp_saved_model_1layer.ckpt')\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.000554033 Train auc= 0.999996 Time elapsed= 0:00:02.332990\n",
      "Epoch: 0002 cost= 0.000101615 Train auc= 0.999996 Time elapsed= 0:00:02.932059\n",
      "Epoch: 0003 cost= 0.000082424 Train auc= 0.999822 Time elapsed= 0:00:03.577395\n",
      "Epoch: 0004 cost= 0.000046042 Train auc= 0.999816 Time elapsed= 0:00:04.228541\n",
      "Epoch: 0005 cost= 0.000051611 Train auc= 0.999816 Time elapsed= 0:00:04.827631\n",
      "Epoch: 0006 cost= 0.000036241 Train auc= 0.999816 Time elapsed= 0:00:05.480811\n",
      "Epoch: 0007 cost= 0.000044642 Train auc= 0.999816 Time elapsed= 0:00:06.045917\n",
      "Epoch: 0008 cost= 0.000061244 Train auc= 0.999816 Time elapsed= 0:00:06.612897\n",
      "Epoch: 0009 cost= 0.000027860 Train auc= 0.999816 Time elapsed= 0:00:07.163090\n",
      "Epoch: 0010 cost= 0.000059302 Train auc= 0.999816 Time elapsed= 0:00:07.699002\n",
      "Epoch: 0011 cost= 0.000059954 Train auc= 0.999804 Time elapsed= 0:00:08.242339\n",
      "Epoch: 0012 cost= 0.000036473 Train auc= 0.999662 Time elapsed= 0:00:08.784968\n",
      "Epoch: 0013 cost= 0.000025311 Train auc= 0.999880 Time elapsed= 0:00:09.326879\n",
      "Epoch: 0014 cost= 0.000026002 Train auc= 0.999850 Time elapsed= 0:00:09.910677\n",
      "Epoch: 0015 cost= 0.000044955 Train auc= 0.999984 Time elapsed= 0:00:10.525605\n",
      "Epoch: 0016 cost= 0.000052626 Train auc= 0.999696 Time elapsed= 0:00:11.088875\n",
      "Epoch: 0017 cost= 0.000037952 Train auc= 0.999984 Time elapsed= 0:00:11.682162\n",
      "Epoch: 0018 cost= 0.000044092 Train auc= 0.999958 Time elapsed= 0:00:12.248782\n",
      "Epoch: 0019 cost= 0.000039153 Train auc= 0.999984 Time elapsed= 0:00:12.786904\n",
      "Epoch: 0020 cost= 0.000031778 Train auc= 0.999880 Time elapsed= 0:00:13.378612\n",
      "Optimization Finished!\n",
      "Model saved in file: ./temp_saved_model_1layer.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    now = datetime.now()\n",
    "    sess.run(init)\n",
    "    total_batch = int(train_x.shape[0]/batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_idx = np.random.choice(train_x.shape[0], batch_size)\n",
    "            batch_xs = train_x[batch_idx]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            train_batch_mse = sess.run(batch_mse, feed_dict={X: train_x})\n",
    "            #print(\"========= Batch MSE Shape =========\")\n",
    "            #print(batch_mse.shape)\n",
    "            #print(train_batch_mse.shape)\n",
    "            #print(type(batch_mse))\n",
    "            #print(\"====================TRAIN BATCH MSE=======================\")\n",
    "            #print(train_batch_mse)\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "                  \"cost=\", \"{:.9f}\".format(c), \n",
    "                  \"Train auc=\", \"{:.6f}\".format(auc(train_y, train_batch_mse)), \n",
    "                  \"Time elapsed=\", \"{}\".format(datetime.now() - now))\n",
    "            #print(\"Epoch:\"+ str((epoch+1)))\n",
    "        #print(\"cost=\" + str(c)) \n",
    "            #print(\"Train auc=\"+ str(auc(train_y, train_batch_mse))) \n",
    "            #print(\"Time elapsed=\"+ str(datetime.now() - now)))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    save_path = saver.save(sess, save_model)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./temp_saved_model_1layer.ckpt\n"
     ]
    }
   ],
   "source": [
    "# ### Test model - on later 25% test data\n",
    "\n",
    "save_model = os.path.join(data_dir, 'temp_saved_model_1layer.ckpt')\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    now = datetime.now()\n",
    "    \n",
    "    saver.restore(sess, save_model)\n",
    "    \n",
    "    test_batch_mse = sess.run(batch_mse, feed_dict={X: test_x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRE_TEST = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's, for example, use 2 as our detection threshold: \n",
      "Number of detected cases above treshold: 33, \n",
      "Number of pos cases only above threshold: 33, \n",
      "The percentage of accuracy above treshold (Precision): 100.00%. \n",
      "Compared to the average percentage of malicious traffic in test set: 0.132%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/corpnva8419mbp/anaconda/envs/deeplearning/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's, for example, use 2 as our detection threshold: \\nNumber of detected cases above treshold: {}, \\nNumber of pos cases only above threshold: {}, \\nThe percentage of accuracy above treshold (Precision): {:0.2f}%. \\nCompared to the average percentage of malicious traffic in test set: 0.132%\".format( np.sum(test_batch_mse > THRE_TEST), np.sum(test_y[test_batch_mse > THRE_TEST]), np.sum(test_y[test_batch_mse > THRE_TEST]) / np.sum(test_batch_mse > THRE_TEST) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/corpnva8419mbp/anaconda/envs/deeplearning/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRE_TEST = 0.0003\n",
    "test_y[test_batch_mse >= THRE_TEST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120f14f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(np.array(test_batch_mse), marker='o', ms=5.5, linestyle='')\n",
    "            \n",
    "ax.hlines(.004, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "plt.title(\"Reconstruction error for test set\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUHm+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e6da630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(test_batch_mse[test_y == 1], marker='o', ms=5.5, linestyle='', color='r')\n",
    "#ax.plot(test_batch_mse[test_y == 0], marker='o', ms=5.5, linestyle='', color='b')\n",
    "#ax.hlines(.0004, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"b\", zorder=100, label='Threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./temp_saved_model_1layer.ckpt\n"
     ]
    }
   ],
   "source": [
    "# ## This dataset comes from Kaggle - https://www.kaggle.com/dalpozz/creditcardfraud\n",
    "# ## This tutorial demonstrates how to use unsupervised training for fraud detection. The main model implemented here is auto-encoder, which achives 0.95 of AUC on test set. \n",
    "# ### Author: Weimin Wang\n",
    "# ### Date: June 18, 2017\n",
    "\n",
    "\n",
    "# Taken from https://github.com/aaxwaz/Fraud-detection-using-deep-learning/blob/master/auto-encoder/autoencoder_demo.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from datetime import datetime \n",
    "from sklearn.metrics import roc_auc_score as auc \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# ### Test model - on later 25% test data\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "save_model = os.path.join(data_dir, 'temp_saved_model_1layer.ckpt')\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    now = datetime.now()\n",
    "    \n",
    "    saver.restore(sess, save_model)\n",
    "    \n",
    "    test_batch_mse = sess.run(batch_mse, feed_dict={X: test_x})\n",
    "    \n",
    "    #print(\"Test auc score: {:.6f}\".format(auc(test_y, test_batch_mse)))\n",
    "    #print(\"Test auc score: \" + str(auc(test_y, test_batch_mse)))\n",
    "    \n",
    "\n",
    "\n",
    "##### ## Visualize the prediction\n",
    "####\n",
    "##### ### 1. Display fraud score (mse) distribution for non-fraud cases\n",
    "####\n",
    "##### In[22]:\n",
    "####\n",
    "####\n",
    "####plt.hist(test_batch_mse[test_y == 0.0], bins = 100)\n",
    "####plt.title(\"fraud score (mse) distribution of non-fraud cases.\")\n",
    "####plt.xlabel(\"fraud score (mse)\")\n",
    "####plt.show()\n",
    "####\n",
    "####\n",
    "##### ### Zoom into (0, 20) range\n",
    "####\n",
    "##### In[24]:\n",
    "####\n",
    "####\n",
    "####plt.hist(test_batch_mse[(test_y == 0.0) & (test_batch_mse < 20)], bins = 100)\n",
    "####plt.title(\"fraud score (mse) distribution for non-fraud cases.\")\n",
    "####plt.xlabel(\"fraud score (mse)\")\n",
    "####plt.show()\n",
    "####\n",
    "####\n",
    "##### ### 2. Display fraud score (mse) distribution for fraud cases\n",
    "####\n",
    "##### In[25]:\n",
    "####\n",
    "####\n",
    "####plt.hist(test_batch_mse[test_y == 1.0], bins = 100)\n",
    "####plt.title(\"fraud score (mse) distribution for fraud cases.\")\n",
    "####plt.xlabel(\"fraud score (mse)\")\n",
    "####plt.show()\n",
    "####\n",
    "####\n",
    "##### In[28]:\n",
    "####\n",
    "####\n",
    "####THRE_TEST = 7\n",
    "####print(\"Let's, for example, use 7 as our detection threshold: \\nNumber of detected cases above treshold: {}, \\nNumber of pos cases only above threshold: {}, \\nThe percentage of accuracy above treshold (Precision): {:0.2f}%. \\nCompared to the average percentage of fraud in test set: 0.132%\".format( np.sum(test_batch_mse > THRE_TEST), np.sum(test_y[test_batch_mse > THRE_TEST]), np.sum(test_y[test_batch_mse > THRE_TEST]) / np.sum(test_batch_mse > THRE_TEST) * 100))\n",
    "####      \n",
    "####\n",
    "####\n",
    "##### ### Observation: Our precision increased by a factor of 60 from 0.132% to 7.86%; However, the detection precision is still low (below 8%), but this is mainly due to the overall percentage of fraud cases is really too low. \n",
    "####\n",
    "##### ## 2. Build a binary classifier that predicts fraud, using the auto-encoder embedding layers as model inputs. \n",
    "####\n",
    "##### ### 1) Get auto-encoder embedding (the `encoder_op` tensor) for both train and test data\n",
    "####\n",
    "##### In[45]:\n",
    "####\n",
    "####\n",
    "####save_model = os.path.join(data_dir, 'temp_saved_model_1layer.ckpt')\n",
    "####saver = tf.train.Saver()\n",
    "####\n",
    "##### Initializing the variables\n",
    "####init = tf.global_variables_initializer()\n",
    "####\n",
    "####with tf.Session() as sess:\n",
    "####    now = datetime.now()\n",
    "####    saver.restore(sess, save_model)\n",
    "####    \n",
    "####    test_encoding = sess.run(encoder_op, feed_dict={X: test_x})\n",
    "####    train_encoding = sess.run(encoder_op, feed_dict={X: train_x})\n",
    "####    \n",
    "####    print(\"Dim for test_encoding and train_encoding are: \\n\", test_encoding.shape, '\\n', train_encoding.shape)\n",
    "####\n",
    "####\n",
    "##### ### 2) Build the graph for FC layers (best hidden size based on validation is found to be 4)\n",
    "####\n",
    "##### In[46]:\n",
    "####\n",
    "####\n",
    "#####n_input = test_encoding.shape[1]\n",
    "####n_input = test_encoding.shape[1]\n",
    "####\n",
    "####hidden_size = 4\n",
    "####output_size = 2\n",
    "####\n",
    "####X = tf.placeholder(tf.float32, [None, n_input], name='input_x')\n",
    "####y_ = tf.placeholder(tf.int32, shape=[None, output_size], name='target_y')\n",
    "####\n",
    "####weights = {\n",
    "####    'W1': tf.Variable(tf.truncated_normal([n_input, hidden_size])),\n",
    "####    'W2': tf.Variable(tf.truncated_normal([hidden_size, output_size])),\n",
    "####}\n",
    "####biases = {\n",
    "####    'b1': tf.Variable(tf.zeros([hidden_size])),\n",
    "####    'b2': tf.Variable(tf.zeros([output_size])),\n",
    "####}\n",
    "####\n",
    "####hidden_layer =  tf.nn.relu(tf.add(tf.matmul(X, weights['W1']), biases['b1']))\n",
    "####pred_logits = tf.add(tf.matmul(hidden_layer, weights['W2']), biases['b2'])\n",
    "####pred_probs = tf.nn.softmax(pred_logits)\n",
    "####\n",
    "####cross_entropy = tf.reduce_mean(\n",
    "####    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=pred_logits))\n",
    "####\n",
    "####optimizer = tf.train.AdamOptimizer(2e-4).minimize(cross_entropy)\n",
    "####\n",
    "####\n",
    "##### ### 3) Prepare the data set. \n",
    "##### ### Now we need to re-split the train into train/val, due to supervised training.\n",
    "##### ### We will therefore use 80% of out previous training data as our new training, and the remaining 20% as new validation. (train : val : test = (0.75x0.8) : (0.75x0.2) : (0.25x1.0)). \n",
    "##### ### Finally we start to train our binary classifier\n",
    "####\n",
    "##### In[47]:\n",
    "####\n",
    "####\n",
    "####n_epochs = 80\n",
    "####batch_size = 256\n",
    "####\n",
    "##### PREPARE DATA\n",
    "####VAL_PERC = 0.2\n",
    "####all_y_bin = np.zeros((df.shape[0], 2))\n",
    "####all_y_bin[range(df.shape[0]), df['Class'].values] = 1\n",
    "####\n",
    "####train_enc_x = train_encoding[:int(train_encoding.shape[0] * (1-VAL_PERC))]\n",
    "####train_enc_y = all_y_bin[:int(train_encoding.shape[0] * (1-VAL_PERC))]\n",
    "####\n",
    "####val_enc_x = train_encoding[int(train_encoding.shape[0] * (1-VAL_PERC)):]\n",
    "####val_enc_y = all_y_bin[int(train_encoding.shape[0] * (1-VAL_PERC)):train_encoding.shape[0]]\n",
    "####\n",
    "####test_enc_y = all_y_bin[train_encoding.shape[0]:]\n",
    "####print(\"Num of data for train, val and test are: \\n{}, \\n{}, \\n{}\".format(train_enc_x.shape[0], val_enc_x.shape[0],                                                                         test_encoding.shape[0]))\n",
    "####\n",
    "##### TRAIN STARTS\n",
    "####save_model = os.path.join(data_dir, 'temp_saved_model_FCLayers.ckpt')\n",
    "####saver = tf.train.Saver()\n",
    "####\n",
    "##### Initializing the variables\n",
    "####init = tf.global_variables_initializer()\n",
    "####\n",
    "####with tf.Session() as sess:\n",
    "####    now = datetime.now()\n",
    "####    sess.run(init)\n",
    "####    total_batch = int(train_enc_x.shape[0]/batch_size)\n",
    "####    # Training cycle\n",
    "####    for epoch in range(n_epochs):\n",
    "####        # Loop over all batches\n",
    "####        for i in range(total_batch):\n",
    "####            batch_idx = np.random.choice(train_enc_x.shape[0], batch_size)\n",
    "####            batch_xs = train_enc_x[batch_idx]\n",
    "####            batch_ys = train_enc_y[batch_idx]\n",
    "####\n",
    "####            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "####            _, c = sess.run([optimizer, cross_entropy], feed_dict={X: batch_xs, y_: batch_ys})\n",
    "####            \n",
    "####        # Display logs per epoch step\n",
    "####        if epoch % display_step == 0:\n",
    "####            val_probs = sess.run(pred_probs, feed_dict={X: val_enc_x})\n",
    "####            print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "####                  \"cost=\", \"{:.9f}\".format(c), \n",
    "####                  \"Val auc=\", \"{:.6f}\".format(auc(val_enc_y[:, 1], val_probs[:, 1])), \n",
    "####                  \"Time elapsed=\", \"{}\".format(datetime.now() - now))\n",
    "####\n",
    "####    print(\"Optimization Finished!\")\n",
    "####    \n",
    "####    save_path = saver.save(sess, save_model)\n",
    "####    print(\"Model saved in file: %s\" % save_path)\n",
    "####    \n",
    "####\n",
    "####\n",
    "##### ### 4) Test the model on the same test data as before - improved on AUC slightly - 0.9669\n",
    "####\n",
    "##### In[48]:\n",
    "####\n",
    "####\n",
    "####save_model = os.path.join(data_dir, 'temp_saved_model_FCLayers.ckpt')\n",
    "####saver = tf.train.Saver()\n",
    "##### Initializing the variables\n",
    "####init = tf.global_variables_initializer()\n",
    "####\n",
    "####with tf.Session() as sess:\n",
    "####    now = datetime.now()\n",
    "####    \n",
    "####    saver.restore(sess, save_model)\n",
    "####    \n",
    "####    test_probs = sess.run(pred_probs, feed_dict={X: test_encoding})\n",
    "####    \n",
    "####    print(\"\\nTest auc score: {}\".format(auc(test_enc_y[:, 1], test_probs[:, 1])))\n",
    "####\n",
    "####\n",
    "##### ## 3. (Optional) However, let's test a simple supervisied neural network (two layers FC) from scratch - without using auto-encoder\n",
    "####\n",
    "##### ### 1) Build graph - 28 (input) -> 8 -> 4 -> 2\n",
    "####\n",
    "##### In[44]:\n",
    "####\n",
    "####\n",
    "####n_epochs = 200\n",
    "####batch_size = 256\n",
    "####\n",
    "#####n_input = test_encoding.shape[1]\n",
    "####n_input = train_x.shape[1]\n",
    "####\n",
    "####hidden1_size = 8\n",
    "####hidden2_size = 4\n",
    "####output_size = 2\n",
    "####\n",
    "####X = tf.placeholder(tf.float32, [None, n_input], name='input_x')\n",
    "####y_ = tf.placeholder(tf.int32, shape=[None, output_size], name='target_y')\n",
    "####\n",
    "####weights = {\n",
    "####    'W1': tf.Variable(tf.truncated_normal([n_input, hidden1_size])),\n",
    "####    'W2': tf.Variable(tf.truncated_normal([hidden1_size, hidden2_size])),\n",
    "####    'W3': tf.Variable(tf.truncated_normal([hidden2_size, output_size])),\n",
    "####}\n",
    "####biases = {\n",
    "####    'b1': tf.Variable(tf.zeros([hidden1_size])),\n",
    "####    'b2': tf.Variable(tf.zeros([hidden2_size])),\n",
    "####    'b3': tf.Variable(tf.zeros([output_size])),\n",
    "####}\n",
    "####\n",
    "####hidden1_layer =  tf.nn.relu(tf.add(tf.matmul(X, weights['W1']), biases['b1']))\n",
    "####hidden2_layer =  tf.nn.relu(tf.add(tf.matmul(hidden1_layer, weights['W2']), biases['b2']))\n",
    "####pred_logits = tf.add(tf.matmul(hidden2_layer, weights['W3']), biases['b3'])\n",
    "####pred_probs = tf.nn.softmax(pred_logits)\n",
    "####\n",
    "####cross_entropy = tf.reduce_mean(\n",
    "####    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=pred_logits))\n",
    "####\n",
    "####optimizer = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "####\n",
    "####\n",
    "##### ### 2) Prepare the data set. Now we need to re-split the train into train/val. \n",
    "##### ### Again, we will use 80% of out previous training data as our new training, and the remaining 20% as new validation. (train : val : test = (0.75x0.8) : (0.75x0.2) : (0.25x1.0)).\n",
    "##### \n",
    "####\n",
    "##### In[45]:\n",
    "####\n",
    "####\n",
    "##### PREPARE DATA\n",
    "####VAL_PERC = 0.2\n",
    "####all_y_bin = np.zeros((df.shape[0], 2))\n",
    "####all_y_bin[range(df.shape[0]), df['Class'].values] = 1\n",
    "####\n",
    "####train_enc_x = train_x[:int(train_x.shape[0] * (1-VAL_PERC))]\n",
    "####train_enc_y = all_y_bin[:int(train_x.shape[0] * (1-VAL_PERC))]\n",
    "####\n",
    "####val_enc_x = train_x[int(train_encoding.shape[0] *  (1-VAL_PERC)):]\n",
    "####val_enc_y = all_y_bin[int(train_encoding.shape[0] * (1-VAL_PERC)):train_x.shape[0]]\n",
    "####\n",
    "####test_enc_y = all_y_bin[train_x.shape[0]:]\n",
    "####\n",
    "####print(\"Num of data for train, val and test are: \\n{}, \\n{}, \\n{}\".format(train_enc_x.shape[0], val_enc_x.shape[0],                                                                         test_encoding.shape[0]))\n",
    "##### TRAIN STARTS\n",
    "####save_model = os.path.join(data_dir, 'temp_saved_model_FCNNets_raw.ckpt')\n",
    "####saver = tf.train.Saver()\n",
    "####\n",
    "##### Initializing the variables\n",
    "####init = tf.global_variables_initializer()\n",
    "####\n",
    "####with tf.Session() as sess:\n",
    "####    now = datetime.now()\n",
    "####    sess.run(init)\n",
    "####    total_batch = int(train_enc_x.shape[0]/batch_size)\n",
    "####    # Training cycle\n",
    "####    for epoch in range(n_epochs):\n",
    "####        # Loop over all batches\n",
    "####        for i in range(total_batch):\n",
    "####            batch_idx = np.random.choice(train_enc_x.shape[0], batch_size)\n",
    "####            batch_xs = train_enc_x[batch_idx]\n",
    "####            batch_ys = train_enc_y[batch_idx]\n",
    "####            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "####            _, c = sess.run([optimizer, cross_entropy], feed_dict={X: batch_xs, y_: batch_ys})\n",
    "####            \n",
    "####        # Display logs per epoch step\n",
    "####        if epoch % display_step == 0:\n",
    "####            val_probs = sess.run(pred_probs, feed_dict={X: val_enc_x})\n",
    "####            print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "####                  \"cost=\", \"{:.9f}\".format(c), \n",
    "####                  \"Val auc=\", \"{:.6f}\".format(auc(val_enc_y[:, 1], val_probs[:, 1])), \n",
    "####                  \"Time elapsed=\", \"{}\".format(datetime.now() - now))\n",
    "####\n",
    "####    print(\"Optimization Finished!\")\n",
    "####    \n",
    "####    save_path = saver.save(sess, save_model)\n",
    "####    print(\"Model saved in file: %s\" % save_path)\n",
    "####    \n",
    "####\n",
    "####\n",
    "##### ### 3) Predict on test data\n",
    "####\n",
    "##### In[47]:\n",
    "####\n",
    "####\n",
    "####save_model = os.path.join(data_dir, 'temp_saved_model_FCNNets_raw.ckpt')\n",
    "####saver = tf.train.Saver()\n",
    "##### Initializing the variables\n",
    "####init = tf.global_variables_initializer()\n",
    "####\n",
    "####with tf.Session() as sess:\n",
    "####    now = datetime.now()\n",
    "####    \n",
    "####    saver.restore(sess, save_model)\n",
    "####    \n",
    "####    test_probs = sess.run(pred_probs, feed_dict={X: test_x})\n",
    "####    \n",
    "####    print(\"Test auc score: {}\".format(auc(test_enc_y[:, 1], test_probs[:, 1])))\n",
    "####\n",
    "####\n",
    "##### In[ ]:\n",
    "####\n",
    "####\n",
    "####\n",
    "####\n",
    "####\n",
    "##### In[ ]:\n",
    "####\n",
    "####\n",
    "####\n",
    "####\n",
    "####\n",
    "##### In[ ]:\n",
    "####\n",
    "####\n",
    "####\n",
    "####\n",
    "####\n",
    "##### In[ ]:\n",
    "####\n",
    "####\n",
    "####\n",
    "####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
